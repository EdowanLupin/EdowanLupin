{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds \n",
    "import tensorflow as tf\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
     ]
    }
   ],
   "source": [
    "dataset, info  = tfds.load('imdb_reviews/subwords8k', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "tokenizer = info.features['text'].encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(train_dataset))\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE, tf.compat.v1.data.get_output_shapes(test_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Bidirectional, Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(tokenizer.vocab_size, 64))\n",
    "model1.add(SimpleRNN(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 64)          523840    \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 32)                3104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 526944 (2.01 MB)\n",
      "Trainable params: 526944 (2.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Dense(16, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.api._v1.keras import metrics\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 301s 766ms/step - loss: 0.6938 - acc: 0.5011 - val_loss: 0.6934 - val_acc: 0.4995\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 261s 669ms/step - loss: 0.6928 - acc: 0.5021 - val_loss: 0.6934 - val_acc: 0.4994\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 246s 628ms/step - loss: 0.6913 - acc: 0.5001 - val_loss: 0.6933 - val_acc: 0.4990\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 261s 668ms/step - loss: 0.6889 - acc: 0.5078 - val_loss: 0.6941 - val_acc: 0.4987\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 281s 719ms/step - loss: 0.6872 - acc: 0.5074 - val_loss: 0.6942 - val_acc: 0.4997\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 298s 763ms/step - loss: 0.6868 - acc: 0.5122 - val_loss: 0.6942 - val_acc: 0.5018\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 347s 888ms/step - loss: 0.6858 - acc: 0.5047 - val_loss: 0.6940 - val_acc: 0.5005\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 390s 997ms/step - loss: 0.6850 - acc: 0.5056 - val_loss: 0.6956 - val_acc: 0.5006\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 357s 911ms/step - loss: 0.6840 - acc: 0.5095 - val_loss: 0.6957 - val_acc: 0.5004\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 381s 975ms/step - loss: 0.6853 - acc: 0.5042 - val_loss: 0.6956 - val_acc: 0.5022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1afb39ed710>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(train_dataset, epochs=10, validation_data=test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(tokenizer.vocab_size, 64))\n",
    "model2.add(LSTM(32))\n",
    "model2.add(Dense(16, activation = 'relu'))\n",
    "model2.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 64)          523840    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                12416     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 536801 (2.05 MB)\n",
      "Trainable params: 536801 (2.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 270s 684ms/step - loss: 0.6933 - acc: 0.4991 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 410s 1s/step - loss: 0.6930 - acc: 0.5013 - val_loss: 0.6928 - val_acc: 0.5002\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 381s 976ms/step - loss: 0.6914 - acc: 0.5010 - val_loss: 0.6945 - val_acc: 0.5009\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 322s 824ms/step - loss: 0.6880 - acc: 0.5010 - val_loss: 0.6959 - val_acc: 0.5018\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 357s 914ms/step - loss: 0.6870 - acc: 0.5046 - val_loss: 0.6945 - val_acc: 0.5006\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 277s 708ms/step - loss: 0.6861 - acc: 0.5088 - val_loss: 0.6955 - val_acc: 0.5008\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 284s 726ms/step - loss: 0.6859 - acc: 0.5048 - val_loss: 0.6958 - val_acc: 0.4999\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 320s 819ms/step - loss: 0.6856 - acc: 0.5077 - val_loss: 0.6946 - val_acc: 0.5001\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 304s 778ms/step - loss: 0.6851 - acc: 0.5097 - val_loss: 0.6959 - val_acc: 0.5020\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 226s 578ms/step - loss: 0.6842 - acc: 0.5013 - val_loss: 0.6968 - val_acc: 0.5021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18b1a848750>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_dataset, epochs=10, validation_data=test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bi-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Embedding(tokenizer.vocab_size, 64))\n",
    "model3.add(Bidirectional(LSTM(32)))\n",
    "model3.add(Dense(16, activation = 'relu'))\n",
    "model3.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, None, 64)          523840    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 549729 (2.10 MB)\n",
      "Trainable params: 549729 (2.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 384s 972ms/step - loss: 0.4937 - acc: 0.7526 - val_loss: 0.3883 - val_acc: 0.8348\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 387s 991ms/step - loss: 0.3858 - acc: 0.8424 - val_loss: 0.4654 - val_acc: 0.7971\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 387s 991ms/step - loss: 0.3060 - acc: 0.8831 - val_loss: 0.4742 - val_acc: 0.8085\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 414s 1s/step - loss: 0.2575 - acc: 0.9043 - val_loss: 0.3892 - val_acc: 0.8413\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 426s 1s/step - loss: 0.1994 - acc: 0.9293 - val_loss: 0.4142 - val_acc: 0.8313\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 395s 1s/step - loss: 0.1705 - acc: 0.9405 - val_loss: 0.4477 - val_acc: 0.8375\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 401s 1s/step - loss: 0.2568 - acc: 0.8966 - val_loss: 0.5130 - val_acc: 0.8263\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 408s 1s/step - loss: 0.1574 - acc: 0.9431 - val_loss: 0.5268 - val_acc: 0.8374\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 397s 1s/step - loss: 0.1183 - acc: 0.9605 - val_loss: 0.5476 - val_acc: 0.8236\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 424s 1s/step - loss: 0.1037 - acc: 0.9659 - val_loss: 0.6179 - val_acc: 0.8272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18b1b1fe3d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(train_dataset, epochs=10, validation_data=test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
